{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0368e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import nltk\n",
    "from copy import deepcopy\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6450f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Once upon a time, there lived two monarchs. The king sat on a throne. Also, the queen sat on a throne. Together, they both were seated on thrones.'\n",
    "NGRAM_LIMIT = 10000\n",
    "tokens = nltk.tokenize.word_tokenize(text)\n",
    "tokens_lc = [x.lower() for x in tokens]\n",
    "INDEXES = {x: i for i, x in enumerate(sorted(set(tokens_lc)))}\n",
    "REV_INDEXES = {x: i for i, x in INDEXES.items()}\n",
    "bigrams = list(nltk.bigrams(tokens_lc))\n",
    "bigrams = bigrams[:min(len(bigrams), NGRAM_LIMIT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb97294",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_text = [w1 for w1, w2 in bigrams]\n",
    "y_text = [w2 for w1, w2 in bigrams]\n",
    "\n",
    "x_num = [INDEXES[x] for x in x_text]\n",
    "y_num = [INDEXES[y] for y in y_text]\n",
    "\n",
    "X = keras.utils.to_categorical(x_num, num_classes=len(INDEXES))\n",
    "y = keras.utils.to_categorical(y_num, num_classes=len(INDEXES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e396d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                1536      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 23)                759       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,375\n",
      "Trainable params: 4,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1402 - acc: 0.0294\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.1250 - acc: 0.0588\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1132 - acc: 0.0588\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.1026 - acc: 0.0588\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0921 - acc: 0.0882\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0822 - acc: 0.0882\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0727 - acc: 0.0882\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0631 - acc: 0.1471\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0542 - acc: 0.1176\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.0452 - acc: 0.1176\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.0361 - acc: 0.1471\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0267 - acc: 0.1765\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0172 - acc: 0.1765\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0081 - acc: 0.1765\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9985 - acc: 0.2059\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9890 - acc: 0.2941\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9798 - acc: 0.2941\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9702 - acc: 0.2941\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9605 - acc: 0.2941\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9510 - acc: 0.2941\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9418 - acc: 0.2941\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9323 - acc: 0.4412\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.9234 - acc: 0.4412\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9138 - acc: 0.4412\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9042 - acc: 0.4412\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.8947 - acc: 0.4706\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8841 - acc: 0.4706\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8739 - acc: 0.4706\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8631 - acc: 0.4706\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8525 - acc: 0.4706\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8415 - acc: 0.5000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8311 - acc: 0.5294\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8204 - acc: 0.5000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8094 - acc: 0.5000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7990 - acc: 0.5000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7879 - acc: 0.5000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.7766 - acc: 0.5000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.7648 - acc: 0.5000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7527 - acc: 0.5000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7398 - acc: 0.5000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7270 - acc: 0.5000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.7136 - acc: 0.5000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.7011 - acc: 0.5000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.6882 - acc: 0.5000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.6753 - acc: 0.5000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6623 - acc: 0.5294\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.6492 - acc: 0.5294\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6359 - acc: 0.5294\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6222 - acc: 0.5294\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.6087 - acc: 0.5294\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5945 - acc: 0.5294\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5800 - acc: 0.5588\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5651 - acc: 0.5588\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.5498 - acc: 0.5588\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5347 - acc: 0.5294\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.5184 - acc: 0.5294\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.5026 - acc: 0.5294\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4858 - acc: 0.5294\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4693 - acc: 0.5294\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4518 - acc: 0.5294\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4335 - acc: 0.5294\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.4163 - acc: 0.5294\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3968 - acc: 0.5294\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3789 - acc: 0.5294\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3594 - acc: 0.5294\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3408 - acc: 0.5294\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3218 - acc: 0.5294\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3027 - acc: 0.5294\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2828 - acc: 0.5294\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2641 - acc: 0.5294\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2441 - acc: 0.5588\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2244 - acc: 0.5588\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.2045 - acc: 0.5882\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1853 - acc: 0.5882\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1662 - acc: 0.5882\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1465 - acc: 0.5882\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1279 - acc: 0.5882\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1093 - acc: 0.5882\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 2.0891 - acc: 0.5882\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0682 - acc: 0.5882\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0466 - acc: 0.5882\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0259 - acc: 0.5882\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.0056 - acc: 0.5882\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9871 - acc: 0.6176\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.9685 - acc: 0.6176\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9499 - acc: 0.6176\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.9306 - acc: 0.6176\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.9127 - acc: 0.6176\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8961 - acc: 0.6176\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8790 - acc: 0.6176\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 0s/step - loss: 1.8610 - acc: 0.6176\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8433 - acc: 0.6176\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8247 - acc: 0.6176\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.8052 - acc: 0.6176\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7853 - acc: 0.6176\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7663 - acc: 0.6176\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7469 - acc: 0.6176\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.7276 - acc: 0.6176\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7088 - acc: 0.6176\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6895 - acc: 0.6176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23084c61120>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = keras.models.Sequential()\n",
    "m.add(keras.layers.Dense(64, activation='relu', input_dim=len(INDEXES)))\n",
    "m.add(keras.layers.Dense(32, activation='relu'))\n",
    "m.add(keras.layers.Dense(len(INDEXES), activation='softmax'))\n",
    "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics='acc')\n",
    "m.summary()\n",
    "m.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15951063",
   "metadata": {},
   "outputs": [],
   "source": [
    "newmod = keras.models.clone_model(m)\n",
    "newmod.pop() # Remove last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d191484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    i = INDEXES[word]\n",
    "    onehot = keras.utils.to_categorical([i], num_classes=len(INDEXES))\n",
    "    return newmod.predict(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b80455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05006447 0.         0.06754407 0.08911205 0.         0.13062237\n",
      "  0.11237837 0.         0.13539109 0.04135512 0.09900975 0.\n",
      "  0.         0.00148174 0.07647885 0.         0.03603644 0.\n",
      "  0.2021379  0.         0.06547876 0.         0.         0.\n",
      "  0.         0.2897411  0.1228924  0.         0.         0.1009649\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(get_vector('queen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f1d611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.20444356 0.         0.0072428  0.01023859 0.\n",
      "  0.02600182 0.         0.         0.0441102  0.         0.03709315\n",
      "  0.         0.         0.11913185 0.         0.         0.\n",
      "  0.14938039 0.         0.         0.         0.         0.\n",
      "  0.12239395 0.23037995 0.09291933 0.05400846 0.         0.07376099\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(get_vector('king'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
